# Awesome Graph Neural Network Privacy Attack and Preservation Research Papers
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
![License](https://img.shields.io/github/license/NDS-VU/awesome-gnn-privacy-papers.svg?color=blue)⠀[![NDS-VU](https://img.shields.io/twitter/follow/nds_vu?style=social&logo=twitter)](https://twitter.com/intent/follow?screen_name=nds_vu)⠀

This repository aims to provide links to works about privacy attacks and privacy preservation on graph data with Graph Neural Networks (GNNs).

### Contents

* [1. Survey Papers](#1-survey-papers)
* [2. GNN Privacy Attack Papers](#2-gnn-privacy-attack-papers)
	* [2.1 Membership Inference Attack](#21-membership-inference-attack)
	* [2.2 Link Inference Attack](#22-link-inference-attack)
  * [2.3 Attribute Inference Attack](#23-attribute-inference-attack) 
* [3. GNN Privacy Preservation Papers](#3-gnn-privacy-preservation-papers)
	* [3.1 Latent Factor Disentangling](#31-latent-factor-disentangling)
	* [3.2 Adversarial Training](#32-adversarial-training)
	* [3.3 Perturbation-based Approaches](#33-perturbation-based-approaches)

## 1. Survey Papers
1. **A Survey on Graph Neural Network Privacy Attacks and Preservation (coming soon!).**
   *authors include NDS Lab members.* 
1. **GNN Surveys (to be added).**
1. **Privacy in ML (to be added.**
 

## 2. GNN Privacy Attack Papers
### 2.1 Membership Inference Attack
1. **Membership Inference Attack on Graph Neural Networks.** *Iyiola E. Olatunji,Wolfgang Nejdl, and Megha Khosla.* arXiv 2021. [[paper]](https://arxiv.org/pdf/2101.06570.pdf)
2. **Node-Level Membership Inference Attacks Against Graph Neural Networks.** *Xinlei He, Rui Wen, Yixin Wu, Michael Backes, Yun Shen, and Yang Zhang.* arXiv 2021. [[paper]](https://arxiv.org/pdf/2102.05429.pdf)
3. **Quantifying Privacy Leakage in Graph Embedding.** *Vasisht Duddu, Antoine Boutet, and Virat Shejwalkar.* arXiv 2021. [[paper]](https://arxiv.org/pdf/2010.00906.pdf)

### 2.2 Link Inference Attack
1. **Stealing Links from Graph Neural Networks.** *Xinlei He, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, and Yang Zhang.* USENIX Security 2021. [[paper]](https://www.usenix.org/system/files/sec21summer_he.pdf)
2. **Quantifying Privacy Leakage in Graph Embedding** *Vasisht Duddu, Antoine Boutet, and Virat Shejwalkar.* arXiv 2021. [[paper]](https://arxiv.org/pdf/2010.00906.pdf)
3. **GraphMI: Extracting Private Graph Data from Graph Neural Networks.** *Zaixi Zhang, Qi Liu, Zhenya Huang, Hao Wang, Chengqiang Lu, Chuanren Liu, and Enhong Chen.* arXiv 2021. [[paper]](https://arxiv.org/pdf/2106.02820.pdf)[[code]](https://github.com/zaixizhang/GraphMI)

### 2.3 Attribute Inference Attack
1. **example title 1.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)
1. **example title 2.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)

## 3. GNN Privacy Preservation Papers
### 3.1 Latent Factor Disentangling
1. **example title 1.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)
1. **example title 2.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)

### 3.2 Adversarial Training
1. **example title 1.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)
1. **example title 2.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)

### 3.3 Perturbation-based Approaches
1. **example title 1.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)
1. **example title 2.** CONFERENCE/arXiv 2021. [[paper]](url to paper pdf)[[code]](url to code)

**License**

- [CC0 Universal](https://github.com/benedekrozemberczki/awesome-community-detection/blob/master/LICENSE)
